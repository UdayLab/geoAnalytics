{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c847f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://www.dropbox.com/scl/fi/jqcoempaqc4v3olxpgz94/sst.mon.anom.1982-2022.nc?rlkey=ob164gtkpjwdwjll1ch5kwp3d&e=1&dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87084ac4-a396-4615-a3c3-bc1bef65ea93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = 'sst.mon.anom.1982-2022.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2fe378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarun/.local/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/tarun/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from geoAnalytics import _repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc9d6154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PostgreSQL 13.15 (Ubuntu 13.15-1.pgdg22.04+1) on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0, 64-bit',)\n",
      "You are now connected\n"
     ]
    }
   ],
   "source": [
    "repository.connect('tarun', '163.143.165.143', 'tarun', 'tarun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25060a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test deleted successfully\n",
      "Repository connection closed.\n"
     ]
    }
   ],
   "source": [
    "repository.delete('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f41a160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository created\n",
      "Repository connection closed.\n"
     ]
    }
   ],
   "source": [
    "repository.create('test', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458bb263",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository.insertRaster('test', file, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1edba2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting raster from database\n",
      "Getting dataframe from database\n",
      "Dataframe created\n",
      "Repository connection closed.\n",
      "Creating raster file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarun/.local/lib/python3.10/site-packages/geoAnalytics/repository.py:563: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dataFrameEnvelope = pd.read_sql_query(query, conn)\n",
      "Warning 1: Several drivers matching nc extension. Using NETCDF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '')\n",
      "(0, '')\n",
      "(0, '')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning 1: Several drivers matching nc extension. Using NETCDF\n",
      "Warning 1: Several drivers matching nc extension. Using NETCDF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'cdo    cat: Processed 300 values from 3 variables over 3 timesteps [0.04s 44MB].')\n",
      "(0, '')\n"
     ]
    }
   ],
   "source": [
    "df = repository.getRaster('test', 'temp', 100, 50, 110, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc5f5139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataframe from database\n",
      "Dataframe created\n",
      "Repository connection closed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarun/.local/lib/python3.10/site-packages/geoAnalytics/repository.py:489: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dataFrameEnvelope = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>89.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5</td>\n",
       "      <td>89.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>89.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.5</td>\n",
       "      <td>89.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.5</td>\n",
       "      <td>89.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64795</th>\n",
       "      <td>355.5</td>\n",
       "      <td>-89.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64796</th>\n",
       "      <td>356.5</td>\n",
       "      <td>-89.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64797</th>\n",
       "      <td>357.5</td>\n",
       "      <td>-89.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64798</th>\n",
       "      <td>358.5</td>\n",
       "      <td>-89.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64799</th>\n",
       "      <td>359.5</td>\n",
       "      <td>-89.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x     y       b1       b2       b3\n",
       "0        0.5  89.5      0.0      0.0      0.0\n",
       "1        1.5  89.5      0.0      0.0      0.0\n",
       "2        2.5  89.5      0.0      0.0      0.0\n",
       "3        3.5  89.5      0.0      0.0      0.0\n",
       "4        4.5  89.5      0.0      0.0      0.0\n",
       "...      ...   ...      ...      ...      ...\n",
       "64795  355.5 -89.5  65534.0  65534.0  65534.0\n",
       "64796  356.5 -89.5  65534.0  65534.0  65534.0\n",
       "64797  357.5 -89.5  65534.0  65534.0  65534.0\n",
       "64798  358.5 -89.5  65534.0  65534.0  65534.0\n",
       "64799  359.5 -89.5  65534.0  65534.0  65534.0\n",
       "\n",
       "[64800 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repository.getDataframe('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f11612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataframe from database\n",
      "Dataframe created\n",
      "Repository connection closed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarun/.local/lib/python3.10/site-packages/geoAnalytics/repository.py:563: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dataFrameEnvelope = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.5</td>\n",
       "      <td>59.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.5</td>\n",
       "      <td>59.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.5</td>\n",
       "      <td>59.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.5</td>\n",
       "      <td>59.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.5</td>\n",
       "      <td>59.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>105.5</td>\n",
       "      <td>50.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>106.5</td>\n",
       "      <td>50.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>107.5</td>\n",
       "      <td>50.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>108.5</td>\n",
       "      <td>50.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>109.5</td>\n",
       "      <td>50.5</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "      <td>65534.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x     y       b1       b2       b3\n",
       "0   100.5  59.5  65534.0  65534.0  65534.0\n",
       "1   101.5  59.5  65534.0  65534.0  65534.0\n",
       "2   102.5  59.5  65534.0  65534.0  65534.0\n",
       "3   103.5  59.5  65534.0  65534.0  65534.0\n",
       "4   104.5  59.5  65534.0  65534.0  65534.0\n",
       "..    ...   ...      ...      ...      ...\n",
       "95  105.5  50.5  65534.0  65534.0  65534.0\n",
       "96  106.5  50.5  65534.0  65534.0  65534.0\n",
       "97  107.5  50.5  65534.0  65534.0  65534.0\n",
       "98  108.5  50.5  65534.0  65534.0  65534.0\n",
       "99  109.5  50.5  65534.0  65534.0  65534.0\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repository.getDataframeForEnvelope('test', 100, 50, 110, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f32c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47fa703",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PostgreSQL 13.15 (Ubuntu 13.15-1.pgdg22.04+1) on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0, 64-bit',)\n",
      "You are now connected\n"
     ]
    }
   ],
   "source": [
    "from geoAnalytics import GeoDatabaseManager\n",
    "file = 'sst.mon.anom.1982-2022.nc'\n",
    "obj = GeoDatabaseManager()\n",
    "obj.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4094e2da-ec47-4dfb-ae2c-7611058b3d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        WKB Position   B0   B1   B2\n",
      "0  0101000020E6100000000000000000E03F000000000060...  0.0  0.0  0.0\n",
      "1  0101000020E6100000000000000000F83F000000000060...  0.0  0.0  0.0\n",
      "2  0101000020E61000000000000000000440000000000060...  0.0  0.0  0.0\n",
      "3  0101000020E61000000000000000000C40000000000060...  0.0  0.0  0.0\n",
      "4  0101000020E61000000000000000001240000000000060...  0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "df = obj.read_raster(file, 3, 2)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83fc6390-3e6a-42a0-98ac-cc1004994d86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            WKB Position       B0       B1  \\\n",
      "0      0101000020E6100000000000000000E03F000000000060...      0.0      0.0   \n",
      "1      0101000020E6100000000000000000F83F000000000060...      0.0      0.0   \n",
      "2      0101000020E61000000000000000000440000000000060...      0.0      0.0   \n",
      "3      0101000020E61000000000000000000C40000000000060...      0.0      0.0   \n",
      "4      0101000020E61000000000000000001240000000000060...      0.0      0.0   \n",
      "...                                                  ...      ...      ...   \n",
      "64795  0101000020E61000000000000000387640000000000060...  65534.0  65534.0   \n",
      "64796  0101000020E61000000000000000487640000000000060...  65534.0  65534.0   \n",
      "64797  0101000020E61000000000000000587640000000000060...  65534.0  65534.0   \n",
      "64798  0101000020E61000000000000000687640000000000060...  65534.0  65534.0   \n",
      "64799  0101000020E61000000000000000787640000000000060...  65534.0  65534.0   \n",
      "\n",
      "            B2             geometry  longitude  latitude  \n",
      "0          0.0     POINT (0.5 89.5)        0.5      89.5  \n",
      "1          0.0     POINT (1.5 89.5)        1.5      89.5  \n",
      "2          0.0     POINT (2.5 89.5)        2.5      89.5  \n",
      "3          0.0     POINT (3.5 89.5)        3.5      89.5  \n",
      "4          0.0     POINT (4.5 89.5)        4.5      89.5  \n",
      "...        ...                  ...        ...       ...  \n",
      "64795  65534.0  POINT (355.5 -89.5)      355.5     -89.5  \n",
      "64796  65534.0  POINT (356.5 -89.5)      356.5     -89.5  \n",
      "64797  65534.0  POINT (357.5 -89.5)      357.5     -89.5  \n",
      "64798  65534.0  POINT (358.5 -89.5)      358.5     -89.5  \n",
      "64799  65534.0  POINT (359.5 -89.5)      359.5     -89.5  \n",
      "\n",
      "[64800 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df = obj.convertWKB(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139f3edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test deleted successfully\n",
      "Disconnecting from repository\n",
      "Disconnected from repository\n",
      "Repository created\n",
      "Disconnecting from repository\n",
      "Disconnected from repository\n",
      "Disconnecting from repository\n",
      "Disconnected from repository\n"
     ]
    }
   ],
   "source": [
    "obj.delete_repository('test')\n",
    "obj.create_repository('test', 3)\n",
    "obj.insert_raster('test', file, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "031533a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarun/geoData.py:297: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql, self.conn)\n",
      "/home/tarun/geoData.py:284: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql, self.conn)\n",
      "/home/tarun/geoData.py:284: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql, self.conn)\n",
      "Warning 1: Several drivers matching nc extension. Using NETCDF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x     y       b1       b2       b3\n",
      "0        0.5  89.5      0.0      0.0      0.0\n",
      "1        1.5  89.5      0.0      0.0      0.0\n",
      "2        2.5  89.5      0.0      0.0      0.0\n",
      "3        3.5  89.5      0.0      0.0      0.0\n",
      "4        4.5  89.5      0.0      0.0      0.0\n",
      "...      ...   ...      ...      ...      ...\n",
      "64795  355.5 -89.5  65534.0  65534.0  65534.0\n",
      "64796  356.5 -89.5  65534.0  65534.0  65534.0\n",
      "64797  357.5 -89.5  65534.0  65534.0  65534.0\n",
      "64798  358.5 -89.5  65534.0  65534.0  65534.0\n",
      "64799  359.5 -89.5  65534.0  65534.0  65534.0\n",
      "\n",
      "[64800 rows x 5 columns]\n",
      "        x     y       b1       b2       b3\n",
      "0   100.5  59.5  65534.0  65534.0  65534.0\n",
      "1   101.5  59.5  65534.0  65534.0  65534.0\n",
      "2   102.5  59.5  65534.0  65534.0  65534.0\n",
      "3   103.5  59.5  65534.0  65534.0  65534.0\n",
      "4   104.5  59.5  65534.0  65534.0  65534.0\n",
      "..    ...   ...      ...      ...      ...\n",
      "95  105.5  50.5  65534.0  65534.0  65534.0\n",
      "96  106.5  50.5  65534.0  65534.0  65534.0\n",
      "97  107.5  50.5  65534.0  65534.0  65534.0\n",
      "98  108.5  50.5  65534.0  65534.0  65534.0\n",
      "99  109.5  50.5  65534.0  65534.0  65534.0\n",
      "\n",
      "[100 rows x 5 columns]\n",
      "Getting raster from database\n",
      "Creating raster file\n",
      "(0, '')\n",
      "(0, '')\n",
      "(0, '')\n",
      "(0, 'cdo    cat: Processed 300 values from 3 variables over 3 timesteps [0.00s 44MB].')\n",
      "(0, '')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning 1: Several drivers matching nc extension. Using NETCDF\n",
      "Warning 1: Several drivers matching nc extension. Using NETCDF\n"
     ]
    }
   ],
   "source": [
    "print(obj.get_dataframe('test'))\n",
    "print(obj.get_dataframe_for_envelope('test', 100, 50, 110, 60))\n",
    "obj.get_raster('test', 'temp', 100, 50, 110, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e04052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Load and process conversations\n",
    "file = \"convo.txt\"\n",
    "conversations = []\n",
    "\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        conversations.append(line.strip() + '\\n')\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(conversations)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences\n",
    "input_sequences = []\n",
    "for line in conversations:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "# Prepare data\n",
    "input_sequences = np.array(input_sequences)\n",
    "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = TextDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Model definition\n",
    "class TextGenerationModel(nn.Module):\n",
    "    def __init__(self, total_words, embedding_dim, hidden_dim, max_sequence_len):\n",
    "        super(TextGenerationModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(total_words, embedding_dim)\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, total_words)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = x[:, -1, :]  # Get the last output of the LSTM\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = TextGenerationModel(total_words, 100, 150, max_sequence_len).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# Text generation function\n",
    "def generate_text(seed_text, max_sequence_len):\n",
    "    model.eval()\n",
    "    seed_text += '\\n'\n",
    "    generated_text = seed_text\n",
    "    while True:\n",
    "        token_list = tokenizer.texts_to_sequences([generated_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        token_list = torch.tensor(token_list, dtype=torch.long).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(token_list)\n",
    "        \n",
    "        # Get the top 5 predicted words\n",
    "        topk = 5\n",
    "        topk_indices = torch.topk(output, topk, dim=1).indices[0].tolist()\n",
    "        \n",
    "        topk_words = []\n",
    "        for index in topk_indices:\n",
    "            for word, idx in tokenizer.word_index.items():\n",
    "                if idx == index:\n",
    "                    topk_words.append(word)\n",
    "                    break\n",
    "        \n",
    "        print(\"Top 5 predictions:\", topk_words)\n",
    "        \n",
    "        # Select the first predicted word (for continuing the generation)\n",
    "        output_word = topk_words[0]\n",
    "        \n",
    "        if output_word == '\\n':\n",
    "            break\n",
    "        generated_text += \" \" + output_word\n",
    "    return generated_text.strip()\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "# Example text generation\n",
    "print(generate_text(\"Hello\", max_sequence_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e3c143-76bc-4a05-b41a-bc77f3059ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
